{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pose Classification MLP - Implement, Train, and Test**"
      ],
      "metadata": {
        "id": "kpcEh7QQJP7N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoTF8TCbVUFH"
      },
      "outputs": [],
      "source": [
        "# mount to google drive if necessary\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor\n",
        "from tqdm.auto import tqdm\n",
        "import torchsummary"
      ],
      "metadata": {
        "id": "VRkCe8ceVcNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class pose_Dataset(Dataset):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.num_cls = 8\n",
        "    self.file_dir = '/content/gdrive/MyDrive/pose_class'\n",
        "    self.data_lists = [[] for x in range(self.num_cls)]\n",
        "    self.cls_list = []\n",
        "    # set file index to separate files in different classes\n",
        "    file_idx = 0\n",
        "    # accessing to file directory\n",
        "    for path, dirs, files in tqdm(os.walk(self.file_dir)):\n",
        "      # get GT(=class) of a file -> file_cls  ex) 068.left -> file_cls = 68\n",
        "      for dir in dirs:\n",
        "        file_cls = int(dir.split('.')[0])\n",
        "        self.cls_list.append(file_cls)\n",
        "\n",
        "      # loading each data\n",
        "      for file_name in files:\n",
        "        file_path = path + \"/\" + file_name # ex) file_name = 068_0001.txt\n",
        "\n",
        "        # if file format is 'csv'\n",
        "        if file_name.split('.')[-1] == 'csv':\n",
        "          csvdata = pd.read_csv(file_path)\n",
        "          npdata = csvdata.to_numpy().squeeze()\n",
        "          for index in range(npdata.shape[0]):\n",
        "            npdata[index] = float(npdata[index].split(\" \")[-1])\n",
        "          data_ts = torch.from_numpy(npdata[7:].astype('float32')) # get keypoint data of 1st object, convert to tensor\n",
        "        # if file format is 'txt'\n",
        "        elif file_name.split('.')[-1] == 'txt':\n",
        "          f = open(file_path, 'r')\n",
        "          data_str = f.read()\n",
        "          data_str = data_str.replace('(', '').replace(')', '').split(',') # data_str = \"x1, y1, v1, x2, y2, v2, ...\"\n",
        "          data = [float(x) for x in data_str]\n",
        "          data_ts = torch.tensor(data)[0][7:] # get keypoint data of 1st object, convert to tensor\n",
        "          f.close()\n",
        "\n",
        "        # print(f\"{file_idx}, {len(self.data_lists[file_idx])}\")\n",
        "        self.data_lists[file_idx-1].append(data_ts)\n",
        "      file_idx += 1\n",
        "\n",
        "    print(f\"{self.cls_list}\")\n",
        "    # length of total data and category positon\n",
        "    self.total_len = 0\n",
        "    self.cat_pos_list = []\n",
        "\n",
        "    # for indexing, store aggregate number of files\n",
        "    for data_files in self.data_lists:\n",
        "      self.total_len += len(data_files)\n",
        "      self.cat_pos_list.append(self.total_len)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.total_len\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # check category\n",
        "    y = 0\n",
        "    # keyboard input as an output\n",
        "    ki = 0\n",
        "    for cat_limit in self.cat_pos_list:\n",
        "      if idx >= cat_limit:\n",
        "        y += 1\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    # load x from data_lists\n",
        "    if y == 0:\n",
        "      x = self.data_lists[y][idx]\n",
        "      ki = 0\n",
        "    elif y == 1:\n",
        "      x = self.data_lists[y][idx - self.cat_pos_list[y-1]]\n",
        "      ki = 32\n",
        "    elif y == 2:\n",
        "      x = self.data_lists[y][idx - self.cat_pos_list[y-1]]\n",
        "      ki = 68\n",
        "    elif y == 3:\n",
        "      x = self.data_lists[y][idx - self.cat_pos_list[y-1]]\n",
        "      ki = 101\n",
        "    elif y == 4:\n",
        "      x = self.data_lists[y][idx - self.cat_pos_list[y-1]]\n",
        "      ki = 67\n",
        "    elif y == 5:\n",
        "      x = self.data_lists[y][idx - self.cat_pos_list[y-1]]\n",
        "      ki = 100\n",
        "    elif y == 6:\n",
        "      x = self.data_lists[y][idx - self.cat_pos_list[y-1]]\n",
        "      ki = 66\n",
        "    elif y == 7:\n",
        "      x = self.data_lists[y][idx - self.cat_pos_list[y-1]]\n",
        "      ki = 65\n",
        "    else:\n",
        "      x = self.data_lists[y][idx - self.cat_pos_list[y-1]]\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "_HXYK8n_XE7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "pose_ds = pose_Dataset()\n",
        "print(len(pose_ds))\n",
        "trainset, testset = random_split(pose_ds, [8259, 2000], generator=torch.Generator().manual_seed(42))\n",
        "train_loader = DataLoader(trainset, batch_size=1, shuffle=False, num_workers=1)\n",
        "test_loader = DataLoader(testset, batch_size=1, shuffle=True, num_workers=1)"
      ],
      "metadata": {
        "id": "nIFXaTRfVcPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class linear(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(in_features, out_features)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "wTY5ao9PKkql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class pose_class_MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net1 = linear(51, 1000)\n",
        "    self.net2 = linear(1000, 256)\n",
        "    self.net3 = nn.Linear(256, 8)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1)\n",
        "    x = self.net1(x)\n",
        "    x = self.net2(x)\n",
        "    x = self.net3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "FACvbmDnKT2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_c_MLP = pose_class_MLP().to(device)\n",
        "pytorch_total_params = sum(p.numel() for p in p_c_MLP.parameters())\n",
        "print(f\"total params: {pytorch_total_params}\")\n",
        "optimizer = torch.optim.Adam(p_c_MLP.parameters(), lr=1e-4, weight_decay=1e-3)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "hTneV7aVVcRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8293f5-6fe9-4849-a4c7-63faf5d43868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total params: 310312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pretrained model\n",
        "model = pose_class_MLP()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\n",
        "model.float().eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlXvypymNyg-",
        "outputId": "196e37db-df85-49ea-db52-7ba0266bcc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pose_class_MLP(\n",
              "  (net1): linear(\n",
              "    (linear): Linear(in_features=51, out_features=1000, bias=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (net2): linear(\n",
              "    (linear): Linear(in_features=1000, out_features=256, bias=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (net3): Linear(in_features=256, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_c_MLP.train()\n",
        "acc_tot = []\n",
        "for epoch in range(1, 100+1):\n",
        "  p_c_MLP.train()\n",
        "  loss_avg = 0\n",
        "  total_batch = 0\n",
        "  for x, y in tqdm(train_loader):\n",
        "    # initialize the gradients of the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # normalizing in a min-max manner\n",
        "    x = x - x.min()\n",
        "    x = x / x.max()\n",
        "\n",
        "    # one-hot encoding the labels\n",
        "    y = nn.functional.one_hot(y, num_classes=8).squeeze()\n",
        "\n",
        "    # move input and labels to GPU device (else CPU)\n",
        "    x = x.to(device)\n",
        "    y = y.to(device).float()\n",
        "\n",
        "    # forward pass the input to the MLP network\n",
        "    pred = p_c_MLP(x)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = criterion(pred, y)\n",
        "\n",
        "    # perform backward propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # updata the parameters w.r.t. gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # update batch count and average loss\n",
        "    total_batch += 1\n",
        "    loss_avg += loss\n",
        "  loss_avg = loss_avg / total_batch\n",
        "  print(f\"{epoch}: {loss_avg}\")\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    p_c_MLP.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for x, y in tqdm(test_loader):\n",
        "      # normalizing in a min-max manner\n",
        "      x = x - x.min()\n",
        "      x = x / x.max()\n",
        "\n",
        "      # one-hot encoding the labels\n",
        "      y = nn.functional.one_hot(y, num_classes=8).squeeze()\n",
        "\n",
        "      # move input and labels to GPU device (else CPU)\n",
        "      x = x.to(device)\n",
        "      y = y.to(device).float()\n",
        "\n",
        "      # forward pass the input to the MLP network\n",
        "      pred = p_c_MLP(x)\n",
        "      total += 1\n",
        "\n",
        "      # calculate the accuracy of the model\n",
        "      correct += (torch.argmax(pred).cpu() == torch.argmax(y).cpu()).sum()\n",
        "    acc = correct.item() / total * 100\n",
        "    print(f\"accuracy: {acc}%\")\n",
        "    acc_tot.append(acc)"
      ],
      "metadata": {
        "id": "sUALKOLLVcTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the total accuracy for every 10 epoch\n",
        "plt.plot(acc_tot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6N6lmeD6urGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_parallel(model):\n",
        "  return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)"
      ],
      "metadata": {
        "id": "isyCZvwHzmzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the MLP after training\n",
        "save_path = '/content/gdrive/MyDrive/pretrained_MLP/'  # enter the save path\n",
        "file_name = 'pose_class_MLP.pt'\n",
        "PATH = save_path + file_name\n",
        "ckpt = deepcopy(p_c_MLP.module if is_parallel(p_c_MLP) else p_c_MLP).half()\n",
        "torch.save(ckpt.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "RHidTMupVcYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}